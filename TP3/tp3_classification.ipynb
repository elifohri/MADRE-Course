{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6cef1ed",
   "metadata": {},
   "source": [
    "# TP 3: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19544c",
   "metadata": {},
   "source": [
    "## Quick Recap: Classification\n",
    "\n",
    "**Classification** = predicting a **category/label** from data.\n",
    "\n",
    "Examples:\n",
    "- Identify malicious traffic vs normal traffic *(binary)*\n",
    "- Classify network applications (Web, Video, Gaming, VoIP) *(multiclass)*\n",
    "\n",
    "\n",
    "### How Classification Works\n",
    "- Classification is **supervised learning**: the model trains on data with known labels.\n",
    "- The model learns patterns and predicts a **class** for new unseen data, often by estimating **probabilities** first.\n",
    "- A **decision boundary** separates classes in the feature space (e.g., normal vs malicious traffic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8045719",
   "metadata": {},
   "source": [
    "## üìù Exercise 1: K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3d526",
   "metadata": {},
   "source": [
    "### Preparation: Generating \"synthetic\" data\n",
    "\n",
    "- We simulate a simple bank-customer dataset with two groups.  \n",
    "- Each class has different average balance and similar income and we sample points from Gaussian distributions to mimic real financial variation.  \n",
    "- We also create a binary `student` feature and a `default` label (0 or 1).  \n",
    "- This dataset will be used to practice KNN classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0854f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "# Means\n",
    "mu_class0 = [700, 3000]\n",
    "mu_class1 = [1350, 3000]\n",
    "\n",
    "# Covariance matrices\n",
    "cov_class0 = [[70000, 0], [0, 900000]]\n",
    "cov_class1 = [[70000, 0], [0, 900000]]\n",
    "\n",
    "n = 300  # samples per class\n",
    "\n",
    "# Generate 2D Gaussian data: (balance, income)\n",
    "balance0, income0 = np.random.multivariate_normal(mu_class0, cov_class0, n).T\n",
    "balance1, income1 = np.random.multivariate_normal(mu_class1, cov_class1, n).T\n",
    "\n",
    "# Ensure no negative data values\n",
    "balance0 = np.maximum(balance0, 0)\n",
    "income0  = np.maximum(income0, 0)\n",
    "balance1 = np.maximum(balance1, 0)\n",
    "income1  = np.maximum(income1, 0)\n",
    "\n",
    "# Combine classes\n",
    "balance = np.concatenate([balance0, balance1])\n",
    "income  = np.concatenate([income0, income1])\n",
    "\n",
    "# Labels: 0 = class0, 1 = class1\n",
    "labels = np.array([0]*n + [1]*n)\n",
    "\n",
    "# Student indicator\n",
    "max_balance = balance.max()\n",
    "student = (np.random.rand(len(balance)) < (balance / max_balance) / 2).astype(int)\n",
    "\n",
    "# Build dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"balance\": balance,\n",
    "    \"income\": income,\n",
    "    \"student\": student,\n",
    "    \"default\": labels\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the synthetic data\n",
    "plt.scatter(df.balance[df.default==0], df.income[df.default==0], label=\"Class 0\")\n",
    "plt.scatter(df.balance[df.default==1], df.income[df.default==1], label=\"Class 1\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for balance distributions of each class\n",
    "count0, bins0, _ = plt.hist(balance0, bins=15, density=True, alpha=0.6, color='blue', label='Class 0 (Low balance)')\n",
    "count1, bins1, _ = plt.hist(balance1, bins=15, density=True, alpha=0.6, color='red', label='Class 1 (High balance)')\n",
    "\n",
    "plt.plot(\n",
    "    bins0,\n",
    "    1 / np.sqrt(2 * np.pi * cov_class0[0][0]) * np.exp(- (bins0 - mu_class0[0])**2 / (2 * cov_class0[0][0])),\n",
    "    linewidth=2,\n",
    "    color='blue'\n",
    ")\n",
    "plt.plot(\n",
    "    bins1,\n",
    "    1 / np.sqrt(2 * np.pi * cov_class1[0][0]) * np.exp(- (bins1 - mu_class1[0])**2 / (2 * cov_class1[0][0])),\n",
    "    linewidth=2,\n",
    "    color='red'\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be561f0e",
   "metadata": {},
   "source": [
    "### Part A ‚Äî Visualizing the KNN Decision Boundary\n",
    "\n",
    "Using the dataset you created:\n",
    "\n",
    "1. Train a **K-Nearest Neighbors (KNN)** classifier using the entire dataset (no train/test split).  \n",
    "2. Use only the features `balance` and `income`.\n",
    "3. Try the following values of \\( K = 1, 3, 10, 40 \\).\n",
    "\n",
    "For each value of \\( K \\):\n",
    "- Fit the KNN model.\n",
    "- Plot the decision boundary in 2D.\n",
    "- Overlay the data points for both classes on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0407366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Values of k to test\n",
    "k_values = [1, 3, 10, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df662e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108136a3",
   "metadata": {},
   "source": [
    "### Part B ‚Äî Choosing the Best K using Cross-Validation\n",
    "\n",
    "1. Use only the features **`balance`** and **`income`**.\n",
    "2. For \\( K = 1, 2, \\dots, 100 \\):\n",
    "   - Perform cross-validation using `sklearn.model_selection.cross_validate`.\n",
    "   - Use the following scoring metrics:\n",
    "     - `accuracy`\n",
    "     - `roc_auc`\n",
    "     - `neg_mean_absolute_error`\n",
    "   - Record both **Train** and **Test** scores for each metric.\n",
    "\n",
    "3. For each metric, compute the **mean Train** and **mean Test** scores across folds.\n",
    "\n",
    "4. Plot **three figures**:\n",
    "   - Accuracy vs \\( K \\)\n",
    "   - ROC-AUC vs \\( K \\)\n",
    "   - MAE vs \\( K \\)  *(remember: MAE = ‚àí `neg_mean_absolute_error`)*\n",
    "\n",
    "   Each figure should contain **two curves** ‚Äî one for **Train**, one for **Test** ‚Äî with the **x-axis** in **logarithmic** scale and the **y-axis** in **linear** scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f473186",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "- Which value of \\( K \\) gives the best overall performance?\n",
    "- Do Train and Test curves agree on the optimal \\( K \\)?\n",
    "- How does the Test Classification Error change as \\( K \\) increases?\n",
    "- What do these results tell you about **overfitting** and **underfitting** in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f04b2",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2e9a7",
   "metadata": {},
   "source": [
    "## üìù Exercise 2: Binary Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4e2cc",
   "metadata": {},
   "source": [
    "1. **Split the dataset:**\n",
    "   - Divide the data into **Train (70%)** and **Test (30%)** sets.\n",
    "\n",
    "2. **Train the model:**\n",
    "   - Fit a **Logistic Regression** classifier on the training data.\n",
    "   - Predict the label for the first test sample using:\n",
    "\n",
    "     ```python\n",
    "     logistic.predict(X_test[0])\n",
    "     logistic.predict_proba([X_test[0]])\n",
    "     ```\n",
    "   - Observe and describe what these two functions return (class label vs. probability).\n",
    "\n",
    "3. **Compute model accuracy:**\n",
    "   - Use ```logreg.score(X_test, y_test)``` to calculate the **mean prediction accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586402a3",
   "metadata": {},
   "source": [
    "4. **Repeat for multiple splits:**\n",
    "\n",
    "   - Split the dataset in several different random ways.\n",
    "   - For each split:\n",
    "     - Fit the logistic regression model.\n",
    "     - Calculate the **test error rate**.\n",
    "   - Compute the **average test error** over all splits.\n",
    "   - Compare this average error rate to the optimal KNN test error found in Exercise 1.\n",
    "   - Discuss what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5688f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe377f",
   "metadata": {},
   "source": [
    "5. **Analyze model performance:**\n",
    "\n",
    "    - For the last train‚Äìtest split, compute the **confusion matrix**.\n",
    "    - Calculate and report the following performance metrics:\n",
    "      - Accuracy (ACC)\n",
    "      - True Positive Rate (TPR / Recall)\n",
    "      - False Positive Rate (FPR)\n",
    "      - Precision (PPV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceaa194",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4cb40",
   "metadata": {},
   "source": [
    "6. **Repeat using Cross-Validation:**\n",
    "\n",
    "   - Repeat the whole processes using **cross validation**\n",
    "   - Use `sklearn.model_selection.cross_validate` to perform cross-validation on the logistic model.\n",
    "   - Compare the results with the previous test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79606a",
   "metadata": {},
   "source": [
    "## üìù Exercise 3: Multinomial (Softmax) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1c64a",
   "metadata": {},
   "source": [
    "1) **Load the data (same source as the notebook):**\n",
    "\n",
    "   - Quickly inspect with `df.shape`, `df.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace with the correct filename if needed\n",
    "filename = \"network_dataset.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38330544",
   "metadata": {},
   "source": [
    "2) **Create multiclass target variables:**\n",
    "\n",
    "    - Create a **multiclass target variable** called `res` to use in Multinomial Logistic Regression:\n",
    "\n",
    "    - The dataset currently contains a numeric label column called `label_num`, which represents the **resolution** of network traffic (e.g., video streaming quality). Transform this numeric value into three categories:\n",
    "\n",
    "        - **0 ‚Üí Low resolution** (below 240)  \n",
    "        - **1 ‚Üí Mid resolution** (between 240 and 480)  \n",
    "        - **2 ‚Üí High resolution** (480 or above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae00e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "threshold1 = 240\n",
    "threshold2 = 480\n",
    "\n",
    "# Create the 3-class target variable\n",
    "res = [\n",
    "    0 if d < threshold1\n",
    "    else 1 if threshold1 <= d < threshold2\n",
    "    else 2\n",
    "    for d in df['label_num']\n",
    "]\n",
    "\n",
    "# Add to the DataFrame\n",
    "df['res'] = res\n",
    "\n",
    "# Check distribution of classes\n",
    "print(df['res'].value_counts().sort_index())\n",
    "\n",
    "# Preview the new column\n",
    "df[['label_num', 'res']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8bcdbd",
   "metadata": {},
   "source": [
    "3) **Define features (X) and target (y):**\n",
    "\n",
    "    - Now that we‚Äôve created the multiclass target (`res`), we need to separate our data into:\n",
    "\n",
    "        - **X (features):** all columns we‚Äôll use to predict resolution  \n",
    "        - **y (target):** the new `res` column we just created  \n",
    "\n",
    "    - Exclude the target (`res`) and any irrelevant or non-numeric identifiers (e.g., timestamps, IDs) from X. Make sure to check the data types so you know which features are numeric and which are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc61a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324eb7b",
   "metadata": {},
   "source": [
    "4) **Preprocess the data:**\n",
    "\n",
    "    - Before training, we need to preprocess the features:\n",
    "\n",
    "        - Scale numeric columns (so all values are on comparable scales)\n",
    "        - One-hot encode categorical columns (so text-based categories become numbers)\n",
    "        - Combine both preprocessing steps in a ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc96f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafacce9",
   "metadata": {},
   "source": [
    "5) **Build the multinomial logistic regression pipeline:**\n",
    "\n",
    "    - Now we‚Äôll create a pipeline that connects preprocessing and model training in one go.\n",
    "\n",
    "    - Steps inside the pipeline:\n",
    "        1. Apply the preprocessing (`ColumnTransformer`)\n",
    "        2. Train a Logistic Regression model configured for multiclass (softmax) classification.\n",
    "\n",
    "    - Use: ```LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500) ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea024b2",
   "metadata": {},
   "source": [
    "6) **Split the data and train the model:**\n",
    "\n",
    "    - Split the dataset into **training** and **testing** subsets to evaluate performance properly.\n",
    "\n",
    "        - Use an 75/25 split (`test_size=0.25`)\n",
    "        - Set a fixed random seed (`random_state=42`)\n",
    "        - Use **stratify=y** to preserve class proportions\n",
    "        - Fit the pipeline on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d890580",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a8169",
   "metadata": {},
   "source": [
    "7) **Evaluate model performance:**\n",
    "\n",
    "    - Now test your trained model and analyze its performance.\n",
    "        - Accuracy\n",
    "        - Macro F1-score\n",
    "        - Classification report\n",
    "        - Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf38a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
